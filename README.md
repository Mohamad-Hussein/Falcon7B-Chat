# Falcon7B-Chat
This is an attempt to configure a chatbot using the falcon-7b-instruct parameter model to run locally on a machine with &lt;8Gb VRAM. Using 4 bit quantization to reduce memory load.
